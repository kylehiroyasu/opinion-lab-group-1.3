{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kylehiroyasu/opinion-lab-group-1.3/blob/master/notebooks/Load_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Gn3fL5aXATE"
   },
   "source": [
    "# Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THTWE9E3Xxmb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "colab = False\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljjHQWlFW89s"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from getpass import getpass\n",
    "    import urllib\n",
    "    from google.colab import output\n",
    "\n",
    "    user = input('User name: ')\n",
    "    password = getpass('Password: ')\n",
    "    password = urllib.parse.quote(password) # your password is converted into url format\n",
    "    repo_name = \"kylehiroyasu/opinion-lab-group-1.3\"\n",
    "\n",
    "    cmd_string = 'git clone https://{0}:{1}@github.com/{2}.git'.format(user, password, repo_name)\n",
    "\n",
    "    os.system(cmd_string)\n",
    "    # Removing the password from the variable\n",
    "    cmd_string, password = \"\", \"\" \n",
    "\n",
    "    # Remove the output of this cell (removes authetication information)\n",
    "    output.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koutyWVPaSt5"
   },
   "source": [
    "Change the directory to the repository and pull latest changes (if any). Only needed when you are on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5301,
     "status": "ok",
     "timestamp": 1588844033232,
     "user": {
      "displayName": "Sebastian Moser",
      "photoUrl": "",
      "userId": "06455260828129060501"
     },
     "user_tz": -120
    },
    "id": "y-B5aNKKYKiv",
    "outputId": "e428a357-06ef-400d-89d2-1549af8d689a"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    %cd opinion-lab-group-1.3/\n",
    "    ! git pull\n",
    "    ! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYh4WTB2iXbu"
   },
   "source": [
    "Only **execute** the next cells, if you are **local** and you are in the notebooks directory! This is not needed in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibes222\\Documents\\Master\\SS20\\NLPLab\\GitHub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"ls\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5YjY7EEqXxm2"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    %pip install -r requirements.txt\n",
    "    output.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrE_dFCXXxm8"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1588844517775,
     "user": {
      "displayName": "Sebastian Moser",
      "photoUrl": "",
      "userId": "06455260828129060501"
     },
     "user_tz": -120
    },
    "id": "B9wlvHdBXxm9",
    "outputId": "4d17383e-fbc3-4344-bba6-86735750eeed",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibes222\\Documents\\Master\\SS20\\NLPLab\\GitHub\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path(os.getcwd())\n",
    "DATA = ROOT/'data'\n",
    "SRC =  ROOT/'src'\n",
    "RAW_DATA = DATA/'raw'\n",
    "RAW_FILES = [\n",
    "    'ABSA16_Laptops_Train_SB1.xml',\n",
    "    'ABSA16_Laptops_Test_SB1_GOLD.xml',\n",
    "    'ABSA16_Restaurants_Train_SB1.xml',\n",
    "    'ABSA16_Restaurants_Test_SB1_GOLD.xml'\n",
    "]\n",
    "print(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(SRC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pu6arr6YXxnK"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_94v-Z8XxnK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_NSBl2zap-y"
   },
   "source": [
    "## Data Import and Preprocessing\n",
    "\n",
    "All the data is stored in `data/raw` as `xml` files. The data is stored in an hierarchical format of course with information stored in tags and tag properties.\n",
    "\n",
    "To make the data easier to work with we've created functionality to denormalize the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "81BfhfmTXxnS"
   },
   "outputs": [],
   "source": [
    "laptops_train = preprocess.load_data_as_df(RAW_DATA/RAW_FILES[0])\n",
    "laptops_test = preprocess.load_data_as_df(RAW_DATA/RAW_FILES[1])\n",
    "\n",
    "restaurants_train = preprocess.load_data_as_df(RAW_DATA/RAW_FILES[2])\n",
    "restaurants_test = preprocess.load_data_as_df(RAW_DATA/RAW_FILES[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdVzVT29XxnY"
   },
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1588844525961,
     "user": {
      "displayName": "Sebastian Moser",
      "photoUrl": "",
      "userId": "06455260828129060501"
     },
     "user_tz": -120
    },
    "id": "QFY8B2BdXxnZ",
    "outputId": "c1deadf9-208e-44f4-9a63-fae3514d0078"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>entity</th>\n",
       "      <th>attribute</th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>outofscope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004293</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>negative</td>\n",
       "      <td>1004293:0</td>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004293</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>negative</td>\n",
       "      <td>1004293:1</td>\n",
       "      <td>We , there were four of us , arrived at noon -...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004293</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>negative</td>\n",
       "      <td>1004293:2</td>\n",
       "      <td>They never brought us complimentary noodles , ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004293</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>QUALITY</td>\n",
       "      <td>negative</td>\n",
       "      <td>1004293:3</td>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004293</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>STYLE_OPTIONS</td>\n",
       "      <td>negative</td>\n",
       "      <td>1004293:3</td>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rid      entity      attribute  polarity         id  \\\n",
       "0  1004293  RESTAURANT        GENERAL  negative  1004293:0   \n",
       "1  1004293     SERVICE        GENERAL  negative  1004293:1   \n",
       "2  1004293     SERVICE        GENERAL  negative  1004293:2   \n",
       "3  1004293        FOOD        QUALITY  negative  1004293:3   \n",
       "4  1004293        FOOD  STYLE_OPTIONS  negative  1004293:3   \n",
       "\n",
       "                                                text outofscope  \n",
       "0  Judging from previous posts this used to be a ...        NaN  \n",
       "1  We , there were four of us , arrived at noon -...        NaN  \n",
       "2  They never brought us complimentary noodles , ...        NaN  \n",
       "3  The food was lousy - too sweet or too salty an...        NaN  \n",
       "4  The food was lousy - too sweet or too salty an...        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPfQZdHNXxnf"
   },
   "source": [
    "# Model Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ri6df1S1XxoL"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings, BertEmbeddings\n",
    "\n",
    "from Dataset import dfToDataset, dfToBinarySamplingDatasets\n",
    "from Trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_sampling = False\n",
    "train_attributes = True\n",
    "train_restaurant = True\n",
    "if binary_sampling:\n",
    "    target_class = \"GENERAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "laptop_entities = {\"BATTERY\": 0, \"COMPANY\": 1, \"CPU\": 2, \"DISPLAY\": 3, \"FANS_COOLING\": 4, \"GRAPHICS\": 5, \"HARDWARE\": 6, \"HARD_DISC\": 7, \"KEYBOARD\": 8, \"LAPTOP\": 9, \"MEMORY\": 10, \"MOTHERBOARD\": 11, \"MOUSE\": 12, \"MULTIMEDIA_DEVICES\": 13, \"OPTICAL_DRIVES\": 14, \"OS\": 15, \"PORTS\": 16, \"POWER_SUPPLY\": 17, \"SHIPPING\": 18, \"SOFTWARE\": 19, \"SUPPORT\": 20, \"WARRANTY\": 21, \"NaN\": 22}\n",
    "laptop_attributes = {\"CONNECTIVITY\": 0, \"DESIGN_FEATURES\": 1, \"GENERAL\": 2, \"MISCELLANEOUS\": 3, \"OPERATION_PERFORMANCE\": 4,\"PORTABILITY\": 5, \"PRICE\": 6, \"QUALITY\": 7, \"USABILITY\": 8, \"NaN\": 9}\n",
    "restaurant_entities = {\"AMBIENCE\": 0, \"DRINKS\": 1, \"FOOD\": 2, \"LOCATION\": 3, \"RESTAURANT\": 4, \"SERVICE\": 5, \"NaN\": 6}\n",
    "restaurant_attributes = {\"GENERAL\": 0, \"MISCELLANEOUS\": 1, \"PRICES\": 2, \"QUALITY\": 3, \"STYLE_OPTIONS\": 4, \"NaN\": 5}\n",
    "\n",
    "if train_restaurant:\n",
    "    train_set = restaurants_train\n",
    "    test_set = restaurants_test\n",
    "    entities = restaurant_entities\n",
    "    attributes = restaurant_attributes\n",
    "else:\n",
    "    train_set = laptops_train\n",
    "    test_set = laptops_test\n",
    "    entities = laptops_entities\n",
    "    attributes = laptops_attributes\n",
    "    \n",
    "embeddings = BertEmbeddings()\n",
    "hidden_dim = 3072\n",
    "# This is the dimension of the output of the ABAE model, the classification model gets this as input\n",
    "# It does not need to be related to the number of classes etc.\n",
    "output_dim = len(attributes if train_attributes else entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create datasets based on whether we want to have a direct binary output (which can be interpreted as a class assignment) or outputs for each class. The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not binary_sampling:\n",
    "    train_dataset = dfToDataset(train_set, entities, attributes, embeddings)\n",
    "    test_dataset = dfToDataset(test_set, entities, attributes, embeddings)\n",
    "else:\n",
    "    train_dataset, other_train_dataset = dfToBinarySamplingDatasets(train_set, train_attributes, \n",
    "                                                                    target_class, embeddings)\n",
    "    test_dataset, other_test_dataset = dfToBinarySamplingDatasets(test_set, train_attributes, \n",
    "                                                                    target_class, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell trains the model based on the given parameters. Be aware that in this step it is not possible to get any classification scores, if you are not using the with_supervised parameter as the training is done purely unsupervised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter:\n",
    "- embedding_dim {int} -- the size of the input embeddings to the model\n",
    "- output_dim {int} -- the output size of the ABAE model -> this can be varied\n",
    "- classification_dim {int} -- the output size of the classification model trained afterwards. It receives output_dim as input and produces the classification (binary or all classes)\n",
    "- epochs {int} -- number of iterations \n",
    "- lr {float} -- learning rate used\n",
    "- batch_size {int} -- number of samples in a batch\n",
    "- use_padding {bool} -- wheter to use padding in the model otherwise each sentence is processed one after the other\n",
    "    validation_percentage {[0,1]} -- how much data should be used for validation, percentage of train_dataset\n",
    "    binary_sampling_percentage {[0,1]} -- how large the batch_size of the other classes should be for a given batch_size\n",
    "        of same samples (only used in binary_sampling)\n",
    "    cuda {bool} -- whether to use the GPU\n",
    "    use_kcl {bool} -- whether to use the KCL objective function or MCL\n",
    "    with_supervised {bool} -- whether to use an additional supervised objective while training ABAE\n",
    "    use_micro_average {bool} -- whether to use micro averaging in metric calculation, otherwise macro average\n",
    "    train_entities {bool} -- whether to train on the entities (or alternative attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Using CPU',)\n",
      "('Epoch:', 0)\n",
      "('Train loss:', 12.598587989807129)\n",
      "('Eval Loss:', 0.9500411152839661)\n",
      "('Epoch:', 1)\n",
      "('Train loss:', 9.820677757263184)\n",
      "('Eval Loss:', 0.8592485189437866)\n",
      "('Epoch:', 2)\n",
      "('Train loss:', 9.146477699279785)\n",
      "('Eval Loss:', 0.9008867740631104)\n",
      "('Epoch:', 3)\n",
      "('Train loss:', 8.54743480682373)\n",
      "('Eval Loss:', 0.95639568567276)\n",
      "('Epoch:', 4)\n",
      "('Train loss:', 8.25543212890625)\n",
      "('Eval Loss:', 0.9274232387542725)\n",
      "('Epoch:', 5)\n",
      "('Train loss:', 7.993363857269287)\n",
      "('Eval Loss:', 0.9095434546470642)\n",
      "('Epoch:', 6)\n",
      "('Train loss:', 7.818665504455566)\n",
      "('Eval Loss:', 0.9087747931480408)\n",
      "('Epoch:', 7)\n",
      "('Train loss:', 7.669414520263672)\n",
      "('Eval Loss:', 0.89202880859375)\n",
      "('Epoch:', 8)\n",
      "('Train loss:', 7.533170700073242)\n",
      "('Eval Loss:', 0.8909785747528076)\n",
      "('Epoch:', 9)\n",
      "('Train loss:', 7.435426235198975)\n",
      "('Eval Loss:', 0.8869544863700867)\n",
      "('Epoch:', 10)\n",
      "('Train loss:', 7.3315534591674805)\n",
      "('Eval Loss:', 0.8772858381271362)\n",
      "('Epoch:', 11)\n",
      "('Train loss:', 7.2526021003723145)\n",
      "('Eval Loss:', 0.881837010383606)\n",
      "('Epoch:', 12)\n",
      "('Train loss:', 7.167094707489014)\n",
      "('Eval Loss:', 0.8681885600090027)\n",
      "('Epoch:', 13)\n",
      "('Train loss:', 7.090626239776611)\n",
      "('Eval Loss:', 0.8706119060516357)\n",
      "('Epoch:', 14)\n",
      "('Train loss:', 7.002627372741699)\n",
      "('Eval Loss:', 0.8672171831130981)\n",
      "('Epoch:', 15)\n",
      "('Train loss:', 6.927407741546631)\n",
      "('Eval Loss:', 0.8677399754524231)\n",
      "('Epoch:', 16)\n",
      "('Train loss:', 6.871645450592041)\n",
      "('Eval Loss:', 0.8661538362503052)\n",
      "('Epoch:', 17)\n",
      "('Train loss:', 6.804234504699707)\n",
      "('Eval Loss:', 0.8634381294250488)\n",
      "('Epoch:', 18)\n",
      "('Train loss:', 6.746540546417236)\n",
      "('Eval Loss:', 0.8612046837806702)\n",
      "('Epoch:', 19)\n",
      "('Train loss:', 6.6941914558410645)\n",
      "('Eval Loss:', 0.8665158748626709)\n",
      "('Epoch:', 20)\n",
      "('Train loss:', 6.656518936157227)\n",
      "('Eval Loss:', 0.8645052909851074)\n",
      "('Epoch:', 21)\n",
      "('Train loss:', 6.612924575805664)\n",
      "('Eval Loss:', 0.8540840148925781)\n",
      "('Epoch:', 22)\n",
      "('Train loss:', 6.572048664093018)\n",
      "('Eval Loss:', 0.8552740812301636)\n",
      "('Epoch:', 23)\n",
      "('Train loss:', 6.501101970672607)\n",
      "('Eval Loss:', 0.8576845526695251)\n",
      "('Epoch:', 24)\n",
      "('Train loss:', 6.460550785064697)\n",
      "('Eval Loss:', 0.862089216709137)\n",
      "('Epoch:', 25)\n",
      "('Train loss:', 6.44550895690918)\n",
      "('Eval Loss:', 0.8587262034416199)\n",
      "('Epoch:', 26)\n",
      "('Train loss:', 6.411795616149902)\n",
      "('Eval Loss:', 0.859602689743042)\n",
      "('Epoch:', 27)\n",
      "('Train loss:', 6.359521865844727)\n",
      "('Eval Loss:', 0.8555993437767029)\n",
      "('Epoch:', 28)\n",
      "('Train loss:', 6.348624229431152)\n",
      "('Eval Loss:', 0.8560064435005188)\n",
      "('Epoch:', 29)\n",
      "('Train loss:', 6.306841850280762)\n",
      "('Eval Loss:', 0.8480536937713623)\n",
      "('Epoch:', 30)\n",
      "('Train loss:', 6.294356346130371)\n",
      "('Eval Loss:', 0.8609029650688171)\n",
      "('Epoch:', 31)\n",
      "('Train loss:', 6.237970352172852)\n",
      "('Eval Loss:', 0.8526240587234497)\n",
      "('Epoch:', 32)\n",
      "('Train loss:', 6.228895664215088)\n",
      "('Eval Loss:', 0.8522287607192993)\n",
      "('Epoch:', 33)\n",
      "('Train loss:', 6.196900367736816)\n",
      "('Eval Loss:', 0.8433274030685425)\n",
      "('Epoch:', 34)\n",
      "('Train loss:', 6.171851634979248)\n",
      "('Eval Loss:', 0.8522517085075378)\n",
      "('Epoch:', 35)\n",
      "('Train loss:', 6.136427879333496)\n",
      "('Eval Loss:', 0.8540785312652588)\n",
      "('Epoch:', 36)\n",
      "('Train loss:', 6.13148307800293)\n",
      "('Eval Loss:', 0.8542317748069763)\n",
      "('Epoch:', 37)\n",
      "('Train loss:', 6.076898574829102)\n",
      "('Eval Loss:', 0.8456759452819824)\n",
      "('Epoch:', 38)\n",
      "('Train loss:', 6.082499027252197)\n",
      "('Eval Loss:', 0.8593311309814453)\n",
      "('Epoch:', 39)\n",
      "('Train loss:', 6.062413215637207)\n",
      "('Eval Loss:', 0.8502024412155151)\n"
     ]
    }
   ],
   "source": [
    "# params:\n",
    "# embedding_dim {int} -- the size of the embeddings\n",
    "param = {\n",
    "    \"embedding_dim\": hidden_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"classification_dim\": len(attributes if train_attributes else entities) if not binary_sampling else 1,\n",
    "    \"epochs\": 40,\n",
    "    \"lr\": 0.0005,\n",
    "    \"batch_size\": 256,\n",
    "    \"use_padding\": False,\n",
    "    \"validation_percentage\": 0.1,\n",
    "    \"binary_sampling_percentage\": 0.5,\n",
    "    \"cuda\": True,\n",
    "    \"use_kcl\": True,\n",
    "    \"with_supervised\": False,\n",
    "    \"use_micro_average\": True,\n",
    "    \"train_entities\": not train_attributes\n",
    "}\n",
    "\n",
    "if binary_sampling:\n",
    "    trainer = Trainer(train_dataset, param, other_train_dataset)\n",
    "else:\n",
    "    trainer = Trainer(train_dataset, param)\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use a linear layer with softmax/sigmoid afterwards for the mapping. This is done by calling trainer.train_classifier which automatically adds those layers at the end of the previous NN. The parameters of the previous NN can be frozen and the parameters for the training can be changed by assigning new values and passing the parameter dict into the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Using CPU',)\n",
      "('Epoch:', 0)\n",
      "('Train loss:', 17.773771286010742)\n",
      "{'precision': 0.3107142857142857, 'recall': 0.3107142857142857, 'f1': 0.3107142857142857}\n",
      "('Eval Loss:', 1.7825847864151)\n",
      "('Epoch:', 1)\n",
      "('Train loss:', 17.746135711669922)\n",
      "{'precision': 0.325, 'recall': 0.325, 'f1': 0.325}\n",
      "('Eval Loss:', 1.7806860208511353)\n",
      "('Epoch:', 2)\n",
      "('Train loss:', 17.71829605102539)\n",
      "{'precision': 0.31785714285714284, 'recall': 0.31785714285714284, 'f1': 0.31785714285714284}\n",
      "('Eval Loss:', 1.7787470817565918)\n",
      "('Epoch:', 3)\n",
      "('Train loss:', 17.690610885620117)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7768114805221558)\n",
      "('Epoch:', 4)\n",
      "('Train loss:', 17.661699295043945)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7748442888259888)\n",
      "('Epoch:', 5)\n",
      "('Train loss:', 17.632970809936523)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7728466987609863)\n",
      "('Epoch:', 6)\n",
      "('Train loss:', 17.60352897644043)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.770841121673584)\n",
      "('Epoch:', 7)\n",
      "('Train loss:', 17.574565887451172)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7688325643539429)\n",
      "('Epoch:', 8)\n",
      "('Train loss:', 17.543872833251953)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7667843103408813)\n",
      "('Epoch:', 9)\n",
      "('Train loss:', 17.513084411621094)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7647432088851929)\n",
      "('Epoch:', 10)\n",
      "('Train loss:', 17.484214782714844)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7626539468765259)\n",
      "('Epoch:', 11)\n",
      "('Train loss:', 17.45181655883789)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7605568170547485)\n",
      "('Epoch:', 12)\n",
      "('Train loss:', 17.420989990234375)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7584363222122192)\n",
      "('Epoch:', 13)\n",
      "('Train loss:', 17.390905380249023)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7563023567199707)\n",
      "('Epoch:', 14)\n",
      "('Train loss:', 17.35955047607422)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7541595697402954)\n",
      "('Epoch:', 15)\n",
      "('Train loss:', 17.325504302978516)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7519941329956055)\n",
      "('Epoch:', 16)\n",
      "('Train loss:', 17.294269561767578)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.7498141527175903)\n",
      "('Epoch:', 17)\n",
      "('Train loss:', 17.263320922851562)\n",
      "{'precision': 0.3142857142857143, 'recall': 0.3142857142857143, 'f1': 0.3142857142857143}\n",
      "('Eval Loss:', 1.747611403465271)\n",
      "('Epoch:', 18)\n"
     ]
    }
   ],
   "source": [
    "param[\"lr\"] = 0.001\n",
    "param[\"epochs\"] = 40\n",
    "model = trainer.train_classifier(freeze=True, new_param=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Model_Training.ipynb",
   "provenance": [
    {
     "file_id": "1v0c-9iV8azyRXNY4kLTmugJOau4-v_W1",
     "timestamp": 1588842155497
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('opinion': venv)",
   "language": "python",
   "name": "python38264bitopinionvenve00ad8436cb3444eadbcf542ff310e8e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
