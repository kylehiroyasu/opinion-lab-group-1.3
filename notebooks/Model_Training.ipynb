{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kylehiroyasu/opinion-lab-group-1.3/blob/master/notebooks/Load_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Gn3fL5aXATE"
   },
   "source": [
    "# Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THTWE9E3Xxmb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "colab = False\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljjHQWlFW89s"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from getpass import getpass\n",
    "    import urllib\n",
    "    from google.colab import output\n",
    "\n",
    "    user = input('User name: ')\n",
    "    password = getpass('Password: ')\n",
    "    password = urllib.parse.quote(password) # your password is converted into url format\n",
    "    repo_name = \"kylehiroyasu/opinion-lab-group-1.3\"\n",
    "\n",
    "    cmd_string = 'git clone https://{0}:{1}@github.com/{2}.git'.format(user, password, repo_name)\n",
    "\n",
    "    os.system(cmd_string)\n",
    "    # Removing the password from the variable\n",
    "    cmd_string, password = \"\", \"\" \n",
    "\n",
    "    # Remove the output of this cell (removes authetication information)\n",
    "    output.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koutyWVPaSt5"
   },
   "source": [
    "Change the directory to the repository and pull latest changes (if any). Only needed when you are on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5301,
     "status": "ok",
     "timestamp": 1588844033232,
     "user": {
      "displayName": "Sebastian Moser",
      "photoUrl": "",
      "userId": "06455260828129060501"
     },
     "user_tz": -120
    },
    "id": "y-B5aNKKYKiv",
    "outputId": "e428a357-06ef-400d-89d2-1549af8d689a"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    %cd opinion-lab-group-1.3/\n",
    "    ! git pull\n",
    "    ! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYh4WTB2iXbu"
   },
   "source": [
    "Only **execute** the next cells, if you are **local** and you are in the notebooks directory! This is not needed in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ibes222/Documents/Master/NLPLab/GitHub\n",
      "data  notebooks  opinion  README.md  requirements.txt  src\r\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5YjY7EEqXxm2"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    %pip install -r requirements.txt\n",
    "    output.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrE_dFCXXxm8"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1588844517775,
     "user": {
      "displayName": "Sebastian Moser",
      "photoUrl": "",
      "userId": "06455260828129060501"
     },
     "user_tz": -120
    },
    "id": "B9wlvHdBXxm9",
    "outputId": "4d17383e-fbc3-4344-bba6-86735750eeed",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ROOT = Path(os.getcwd())\n",
    "DATA = ROOT/'data'\n",
    "SRC =  ROOT/'src'\n",
    "RAW_DATA = DATA/'raw'\n",
    "RAW_FILES = [\n",
    "    'ABSA16_Laptops_Train_SB1.xml',\n",
    "    'ABSA16_Laptops_Test_SB1_GOLD.xml',\n",
    "    'ABSA16_Restaurants_Train_SB1.xml',\n",
    "    'ABSA16_Restaurants_Test_SB1_GOLD.xml'\n",
    "]\n",
    "print(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(SRC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pu6arr6YXxnK"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_94v-Z8XxnK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_NSBl2zap-y"
   },
   "source": [
    "## Data Import and Preprocessing\n",
    "\n",
    "All the data is stored in `data/raw` as `xml` files. The data is stored in an hierarchical format of course with information stored in tags and tag properties.\n",
    "\n",
    "To make the data easier to work with we've created functionality to denormalize the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "81BfhfmTXxnS"
   },
   "outputs": [],
   "source": [
    "laptops_train = preprocess.load_data_as_df(RAW_DATA/RAW_FILES[0])\n",
    "laptops_test = preprocess.load_data_as_df(RAW_DATA/RAW_FILES[1])\n",
    "\n",
    "restaurants_train = preprocess.load_data_as_df(RAW_DATA/RAW_FILES[2])\n",
    "restaurants_test = preprocess.load_data_as_df(RAW_DATA/RAW_FILES[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdVzVT29XxnY"
   },
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1588844525961,
     "user": {
      "displayName": "Sebastian Moser",
      "photoUrl": "",
      "userId": "06455260828129060501"
     },
     "user_tz": -120
    },
    "id": "QFY8B2BdXxnZ",
    "outputId": "c1deadf9-208e-44f4-9a63-fae3514d0078"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>entity</th>\n",
       "      <th>attribute</th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>outofscope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004293</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>negative</td>\n",
       "      <td>1004293:0</td>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004293</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>negative</td>\n",
       "      <td>1004293:1</td>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004293</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>negative</td>\n",
       "      <td>1004293:2</td>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004293</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>QUALITY</td>\n",
       "      <td>negative</td>\n",
       "      <td>1004293:3</td>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004293</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>STYLE_OPTIONS</td>\n",
       "      <td>negative</td>\n",
       "      <td>1004293:3</td>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rid      entity      attribute  polarity         id  \\\n",
       "0  1004293  RESTAURANT        GENERAL  negative  1004293:0   \n",
       "1  1004293     SERVICE        GENERAL  negative  1004293:1   \n",
       "2  1004293     SERVICE        GENERAL  negative  1004293:2   \n",
       "3  1004293        FOOD        QUALITY  negative  1004293:3   \n",
       "4  1004293        FOOD  STYLE_OPTIONS  negative  1004293:3   \n",
       "\n",
       "                                                text outofscope  \n",
       "0  Judging from previous posts this used to be a ...        NaN  \n",
       "1  We, there were four of us, arrived at noon - t...        NaN  \n",
       "2  They never brought us complimentary noodles, i...        NaN  \n",
       "3  The food was lousy - too sweet or too salty an...        NaN  \n",
       "4  The food was lousy - too sweet or too salty an...        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPfQZdHNXxnf"
   },
   "source": [
    "# Model Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ri6df1S1XxoL"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings, BertEmbeddings\n",
    "\n",
    "from Dataset import dfToDataset, dfToBinarySamplingDatasets\n",
    "from Trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_sampling = False\n",
    "train_attributes = False\n",
    "if binary_sampling:\n",
    "    target_class = \"AMBIENCE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "laptop_entities = {\"BATTERY\": 0, \"COMPANY\": 1, \"CPU\": 2, \"DISPLAY\": 3, \"FANS_COOLING\": 4, \"GRAPHICS\": 5, \"HARDWARE\": 6, \"HARD_DISC\": 7, \"KEYBOARD\": 8, \"LAPTOP\": 9, \"MEMORY\": 10, \"MOTHERBOARD\": 11, \"MOUSE\": 12, \"MULTIMEDIA_DEVICES\": 13, \"OPTICAL_DRIVES\": 14, \"OS\": 15, \"PORTS\": 16, \"POWER_SUPPLY\": 17, \"SHIPPING\": 18, \"SOFTWARE\": 19, \"SUPPORT\": 20, \"WARRANTY\": 21, \"NaN\": 22}\n",
    "laptop_attributes = {\"CONNECTIVITY\": 0, \"DESIGN_FEATURES\": 1, \"GENERAL\": 2, \"MISCELLANEOUS\": 3, \"OPERATION_PERFORMANCE\": 4,\"PORTABILITY\": 5, \"PRICE\": 6, \"QUALITY\": 7, \"USABILITY\": 8, \"NaN\": 9}\n",
    "restaurant_entities = {\"AMBIENCE\": 0, \"DRINKS\": 1, \"FOOD\": 2, \"LOCATION\": 3, \"RESTAURANT\": 4, \"SERVICE\": 5, \"NaN\": 6}\n",
    "restaurant_attributes = {\"GENERAL\": 0, \"MISCELLANEOUS\": 1, \"PRICES\": 2, \"QUALITY\": 3, \"STYLE_OPTIONS\": 4, \"NaN\": 5}\n",
    "\n",
    "embeddings = WordEmbeddings('glove')\n",
    "hidden_dim = 100\n",
    "output_dim = len(restaurant_entities) if not binary_sampling else 1\n",
    "\n",
    "train_set = restaurants_train\n",
    "test_set = restaurants_test\n",
    "entities = restaurant_entities\n",
    "attributes = restaurant_attributes\n",
    "\n",
    "if not binary_sampling:\n",
    "    train_dataset = dfToDataset(train_set, entities, attributes, embeddings)\n",
    "    test_dataset = dfToDataset(test_set, entities, attributes, embeddings)\n",
    "else:\n",
    "    train_dataset, other_train_dataset = dfToBinarySamplingDatasets(train_set, train_attributes, \n",
    "                                                                    target_class, embeddings)\n",
    "    test_dataset, other_test_dataset = dfToBinarySamplingDatasets(test_set, train_attributes, \n",
    "                                                                    target_class, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell trains the model based on the given parameters. Be aware that in this step it is not possible to get any classification scores, if you are not using the with_supervised parameter as the training is done purely unsupervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Using CPU',)\n",
      "('Epoch:', 0)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Input dimension must be 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a1dfc7980585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Master/NLPLab/GitHub/src/Trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_sampling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_bs_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Master/NLPLab/GitHub/src/Trainer.py\u001b[0m in \u001b[0;36mtrain_bs_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Master/NLPLab/GitHub/src/Trainer.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, sentences, target)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monly_supervised\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClass2Simi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner_clustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"with_supervised\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Master/NLPLab/GitHub/src/Learners.py\u001b[0m in \u001b[0;36mcalculate_criterion\u001b[0;34m(self, output, similarity, mask)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \"\"\"\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mprob1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPairEnum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Master/NLPLab/GitHub/src/Loss.py\u001b[0m in \u001b[0;36mPairEnum\u001b[0;34m(x, mask)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# This method is used by the learner to iterate through all possible pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# of similar/disimilar samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Input dimension must be 2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Input dimension must be 2"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    \"embedding_dim\": hidden_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"epochs\": 2,\n",
    "    \"lr\": 0.005,\n",
    "    \"batch_size\": 256,\n",
    "    \"use_padding\": False,\n",
    "    \"validation_percentage\": 0.1,\n",
    "    \"binary_sampling_percentage\": 0.5,\n",
    "    \"cuda\": False,\n",
    "    \"use_kcl\": True,\n",
    "    \"with_supervised\": False,\n",
    "    \"use_micro_average\": True,\n",
    "    \"train_entities\": not train_attributes\n",
    "}\n",
    "\n",
    "if binary_sampling:\n",
    "    trainer = Trainer(train_dataset, param, other_train_dataset)\n",
    "else:\n",
    "    trainer = Trainer(train_dataset, param)\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use a linear layer with softmax/sigmoid afterwards for the mapping. This is done by calling trainer.train_classifier which automatically adds those layers at the end of the previous NN. The parameters of the previous NN can be frozen and the parameters for the training can be changed by assigning new values and passing the parameter dict into the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param[\"lr\"] = 0.01\n",
    "param[\"epochs\"] = 2\n",
    "model = trainer.train_classifier(freeze=True, new_param=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Model_Training.ipynb",
   "provenance": [
    {
     "file_id": "1v0c-9iV8azyRXNY4kLTmugJOau4-v_W1",
     "timestamp": 1588842155497
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('opinion': venv)",
   "language": "python",
   "name": "python37464bitopinionvenv8a064d8f051a400b8fc2adc91efc3902"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
